{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1eWiVVXOqgU",
        "outputId": "a067e5ed-8d6d-475c-b8db-5b13d3845bea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nx-arangodb in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: networkx<=3.4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (3.4)\n",
            "Requirement already satisfied: phenolrs~=0.5 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (0.5.9)\n",
            "Requirement already satisfied: python-arango~=8.1 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (8.1.6)\n",
            "Requirement already satisfied: adbnx-adapter~=5.0.5 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (5.0.6)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (2.32.3)\n",
            "Requirement already satisfied: rich>=12.5.1 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (13.9.4)\n",
            "Requirement already satisfied: setuptools>=45 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (75.1.0)\n",
            "Requirement already satisfied: numpy~=1.26 in /usr/local/lib/python3.11/dist-packages (from phenolrs~=0.5->nx-arangodb) (1.26.4)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (2.3.0)\n",
            "Requirement already satisfied: requests_toolbelt in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (1.0.0)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (2.10.1)\n",
            "Requirement already satisfied: importlib_metadata>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (8.6.1)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (24.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.7.1->python-arango~=8.1->nx-arangodb) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (0.1.2)\n",
            "Thu Mar  6 00:36:50 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Requirement already satisfied: nx-cugraph-cu12 in /usr/local/lib/python3.11/dist-packages (24.12.0)\n",
            "Requirement already satisfied: cupy-cuda12x>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (13.3.0)\n",
            "Requirement already satisfied: networkx>=3.2 in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (3.4)\n",
            "Requirement already satisfied: numpy<3.0a0,>=1.23 in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (1.26.4)\n",
            "Requirement already satisfied: pylibcugraph-cu12==24.12.* in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (24.12.0)\n",
            "Requirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (12.5.3.2)\n",
            "Requirement already satisfied: nvidia-curand-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (10.3.6.82)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (11.6.3.83)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (12.5.1.3)\n",
            "Requirement already satisfied: pylibraft-cu12==24.12.* in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (24.12.0)\n",
            "Requirement already satisfied: rmm-cu12==24.12.* in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (24.12.1)\n",
            "Requirement already satisfied: cuda-python<13.0a0,<=12.6.0,>=12.0 in /usr/local/lib/python3.11/dist-packages (from pylibraft-cu12==24.12.*->pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (12.6.0)\n",
            "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.11/dist-packages (from rmm-cu12==24.12.*->pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (0.61.0)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x>=12.0.0->nx-cugraph-cu12) (0.8.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12->pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (12.5.82)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57->rmm-cu12==24.12.*->pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (0.44.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.20)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.7)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.3.5)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.41)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.8.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.61.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.16)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.1)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.53)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# 1. Install nx-arangodb via pip\n",
        "# Github: https://github.com/arangodb/nx-arangodb\n",
        "\n",
        "!pip install nx-arangodb\n",
        "\n",
        "!nvidia-smi\n",
        "!nvcc --version\n",
        "\n",
        "# 3. Install nx-cugraph via pip\n",
        "# Note: Only enable this installation if the step above is working!\n",
        "\n",
        "!pip install nx-cugraph-cu12 --extra-index-url https://pypi.nvidia.com # Requires CUDA-capable GPU\n",
        "\n",
        "# 4. Install LangChain & LangGraph\n",
        "\n",
        "!pip install --upgrade langchain langchain-community langchain-openai langgraph\n",
        "\n",
        "!pip install networkx matplotlib pandas numpy requests\n",
        "# arango python-arango"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### **2️⃣ Import Required Modules**\n",
        "import networkx as nx\n",
        "import nx_arangodb as nxadb\n",
        "from arango import ArangoClient\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "import re\n",
        "import requests\n",
        "import http.client\n",
        "import json\n",
        "import time\n",
        "import hashlib\n",
        "\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.graphs import ArangoGraph\n",
        "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
        "from langchain_core.tools import tool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LdSQ0bVPdPO",
        "outputId": "9d63a05b-e523-4f5f-9c04-34d22ea40325"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[00:37:59 +0000] [INFO]: NetworkX-cuGraph is available.\n",
            "INFO:nx_arangodb:NetworkX-cuGraph is available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "# 1: Install the dependencies\n",
        "\n",
        "!pip install python-arango # The ArangoDB Python Driver\n",
        "!pip install adb-cloud-connector # The ArangoDB Cloud Instance provisioner\n",
        "!pip install arango-datasets # Datasets package\n",
        "!pip install openai==1.6.1\n",
        "!pip install langchain==0.1.0"
      ],
      "metadata": {
        "id": "o_4CuiyOPeTX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "MBOJtiyePi4b",
        "outputId": "f8c0b79f-8984-4613-976a-3803b6d90d8d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1c625b6b-0d82-4cde-9fea-8ffcd86d5e82\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1c625b6b-0d82-4cde-9fea-8ffcd86d5e82\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving config.env to config.env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables from the file\n",
        "load_dotenv(\"/content/config.env\")  # Update path if needed\n",
        "\n",
        "# Get credentials\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "arango_url = os.getenv(\"ARANGO_URL\")\n",
        "arango_username = os.getenv(\"ARANGO_USERNAME\")\n",
        "arango_password = os.getenv(\"ARANGO_PASSWORD\")\n",
        "arango_dbname = os.getenv(\"ARANGO_DBNAME\")\n",
        "rapidapi_key = os.getenv(\"RAPIDAPI_KEY\")\n",
        "rapidapi_host = os.getenv(\"RAPIDAPI_HOST\")\n"
      ],
      "metadata": {
        "id": "c4NEFijvQLSM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from arango import ArangoClient\n",
        "\n",
        "def setup_arangodb():\n",
        "    global db\n",
        "    try:\n",
        "        print(f\"🔄 Connecting to ArangoDB Cloud at {arango_url}...\")\n",
        "\n",
        "        # ✅ Initialize ArangoDB Client\n",
        "        client = ArangoClient(hosts=arango_url)\n",
        "\n",
        "        # ✅ Connect to the specified database\n",
        "        db = client.db(\n",
        "            arango_dbname,\n",
        "            arango_username,\n",
        "            arango_password,\n",
        "            verify=True  # Secure connection\n",
        "        )\n",
        "\n",
        "        print(f\"✅ Successfully connected to ArangoDB Cloud: {db.name}\")\n",
        "\n",
        "        # ✅ Ensure required collections exist\n",
        "        for collection in [\"hotels\", \"attractions\", \"hotel_links\", \"attraction_links\", \"cities\", \"destinations\", \"flight_destinations\", \"flights\"]:\n",
        "            if not db.has_collection(collection):\n",
        "                db.create_collection(collection)\n",
        "\n",
        "        # ✅ Ensure graph exists\n",
        "        if not db.has_graph('TravelGraph'):\n",
        "            #db.create_graph('TravelGraph')\n",
        "            # Define the graph with edge collections\n",
        "            graph = db.create_graph(\n",
        "                \"TravelGraph\",\n",
        "                edge_definitions=[\n",
        "                    {\n",
        "                        \"edge_collection\": \"flights\",\n",
        "                        \"from_vertex_collections\": [\"cities\"],\n",
        "                        \"to_vertex_collections\": [\"cities\"]\n",
        "                    },\n",
        "                    {\n",
        "                        \"edge_collection\": \"hotel_links\",\n",
        "                        \"from_vertex_collections\": [\"cities\"],\n",
        "                        \"to_vertex_collections\": [\"hotels\"]\n",
        "                    },\n",
        "                    {\n",
        "                        \"edge_collection\": \"attraction_links\",\n",
        "                        \"from_vertex_collections\": [\"cities\"],\n",
        "                        \"to_vertex_collections\": [\"attractions\"]\n",
        "                    }\n",
        "                ]\n",
        "            )\n",
        "\n",
        "        return db\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ ArangoDB Cloud Connection Error: {e}\")\n",
        "        db = None\n",
        "        return None\n",
        "\n",
        "# ✅ Run Setup\n",
        "db = setup_arangodb()\n",
        "print(db.graphs())\n",
        "print(db.collections())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8EsWWyJPpxB",
        "outputId": "366f0f4b-9c84-40c3-f655-4e36584bff11"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Connecting to ArangoDB Cloud at https://c4c335acccb7.arangodb.cloud:8529...\n",
            "✅ Successfully connected to ArangoDB Cloud: Langchain\n",
            "[{'id': '_graphs/TravelGraph', 'name': 'TravelGraph', 'revision': '_jRyRw9W---', 'orphan_collections': [], 'edge_definitions': [], 'shard_count': None, 'replication_factor': None}]\n",
            "[{'id': '1053', 'name': '_queues', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '1052', 'name': '_aqlfunctions', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '1054', 'name': '_jobs', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '537322', 'name': 'hotel_links', 'system': False, 'type': 'document', 'status': 'loaded'}, {'id': '537347', 'name': 'flights', 'system': False, 'type': 'document', 'status': 'loaded'}, {'id': '537332', 'name': 'cities', 'system': False, 'type': 'document', 'status': 'loaded'}, {'id': '1055', 'name': '_apps', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '1056', 'name': '_appbundles', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '1050', 'name': '_graphs', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '537312', 'name': 'hotels', 'system': False, 'type': 'document', 'status': 'loaded'}, {'id': '537327', 'name': 'attraction_links', 'system': False, 'type': 'document', 'status': 'loaded'}, {'id': '537337', 'name': 'destinations', 'system': False, 'type': 'document', 'status': 'loaded'}, {'id': '1057', 'name': '_frontend', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '1051', 'name': '_analyzers', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '537317', 'name': 'attractions', 'system': False, 'type': 'document', 'status': 'loaded'}, {'id': '537342', 'name': 'flight_destinations', 'system': False, 'type': 'document', 'status': 'loaded'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to delete collections in ArangoDB\n",
        "def delete_collections(db, collections):\n",
        "    for collection in collections:\n",
        "        if db.has_collection(collection):\n",
        "            db.delete_collection(collection)  # Correct method to delete the entire collection\n",
        "            print(f\"🗑️ Deleted collection: {collection}\")\n",
        "        else:\n",
        "            print(f\"⚠️ Collection '{collection}' does not exist.\")\n",
        "\n",
        "# List of collections to delete\n",
        "collections_to_delete = [\"hotels\", \"attractions\", \"hotel_links\", \"attraction_links\", \"cities\", \"destinations\", \"flight_destinations\", \"flights\"]\n",
        "\n",
        "# Call the function to delete collections\n",
        "delete_collections(db, collections_to_delete)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdY-_jeO9R14",
        "outputId": "26ad0b70-ef4b-4616-eadb-737cd875e951"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🗑️ Deleted collection: hotels\n",
            "🗑️ Deleted collection: attractions\n",
            "🗑️ Deleted collection: hotel_links\n",
            "🗑️ Deleted collection: attraction_links\n",
            "🗑️ Deleted collection: cities\n",
            "🗑️ Deleted collection: destinations\n",
            "🗑️ Deleted collection: flight_destinations\n",
            "🗑️ Deleted collection: flights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_destination_id(destination):\n",
        "    conn = http.client.HTTPSConnection(rapidapi_host)\n",
        "    headers = {\n",
        "        'x-rapidapi-key': rapidapi_key,\n",
        "        'x-rapidapi-host': rapidapi_host\n",
        "    }\n",
        "\n",
        "    request_url = f\"/api/v1/hotels/searchDestination?query={destination}\"\n",
        "    conn.request(\"GET\", request_url, headers=headers)\n",
        "    res = conn.getresponse()\n",
        "    data = res.read()\n",
        "\n",
        "    try:\n",
        "        destination_data = json.loads(data.decode(\"utf-8\"))\n",
        "        if 'data' in destination_data and isinstance(destination_data['data'], list) and len(destination_data['data']) > 0:\n",
        "            city_destinations = [d for d in destination_data['data'] if d.get('search_type') == 'city']\n",
        "\n",
        "            if not city_destinations:\n",
        "                print(f\"Error: No city-level destinations found for {destination}.\")\n",
        "                return None, None\n",
        "\n",
        "            best_match = city_destinations[0]\n",
        "            dest_id = best_match.get('dest_id', 'N/A')\n",
        "            search_type = best_match.get('search_type', 'N/A')\n",
        "\n",
        "            print(f\"✅ Selected Destination: {best_match.get('name')}, ID: {dest_id}, Type: {search_type}\")\n",
        "            # ✅ **Store destination in the database**\n",
        "            if not db.collection(\"destinations\").has(dest_id):\n",
        "                db.collection(\"destinations\").insert({\n",
        "                    \"_key\": str(dest_id),\n",
        "                    \"name\": best_match.get(\"name\", destination),\n",
        "                    \"dest_id\": dest_id,\n",
        "                    \"search_type\": search_type\n",
        "                })\n",
        "                print(f\"🗺️ Destination '{best_match.get('name')}' added to database.\")\n",
        "\n",
        "            return dest_id, search_type\n",
        "        else:\n",
        "            print(f\"❌ Error: No valid destinations found in API response for {destination}.\")\n",
        "            return None, None\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"❌ Error decoding JSON response for {destination}:\", e)\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "WoBIoR-UQjGN"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import hashlib\n",
        "\n",
        "# Define a global hotel ID counter\n",
        "global_hotel_id = 1\n",
        "\n",
        "def get_hotels_in_destination(destination, arrival_date, departure_date, adults=1, children_age=\"0,17\", room_qty=1, page_number=1, currency=\"USD\"):\n",
        "    global global_hotel_id  # Use the global variable for unique hotel IDs\n",
        "\n",
        "    dest_id, search_type = get_destination_id(destination)\n",
        "    if not dest_id or not search_type:\n",
        "        print(f\"❌ Error: Could not retrieve destination ID for {destination}.\")\n",
        "        return\n",
        "\n",
        "    conn = http.client.HTTPSConnection(rapidapi_host)\n",
        "    headers = {\n",
        "        'x-rapidapi-key': rapidapi_key,\n",
        "        'x-rapidapi-host': rapidapi_host\n",
        "    }\n",
        "\n",
        "    request_url = f\"/api/v1/hotels/searchHotels?dest_id={dest_id}&search_type={search_type}&adults={adults}&children_age={children_age}&room_qty={room_qty}&page_number={page_number}&units=metric&temperature_unit=c&languagecode=en-us&currency_code={currency}&arrival_date={arrival_date}&departure_date={departure_date}\"\n",
        "\n",
        "    conn.request(\"GET\", request_url, headers=headers)\n",
        "    res = conn.getresponse()\n",
        "    data = res.read()\n",
        "\n",
        "    try:\n",
        "        hotels_data = json.loads(data.decode(\"utf-8\"))\n",
        "\n",
        "        # Ensure correct structure\n",
        "        if 'data' in hotels_data and 'hotels' in hotels_data['data']:\n",
        "            hotels_list = hotels_data['data']['hotels']\n",
        "\n",
        "            print(f\"\\n🏨 **Hotels Found in {destination}:**\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            for hotel in hotels_list:\n",
        "                property_info = hotel.get('property', {})\n",
        "\n",
        "                retry_attempts = 2  # Maximum retries if hotel_id is None\n",
        "                wait_time = 0.1  # Seconds to wait between retries\n",
        "\n",
        "                hotel_id = property_info.get('hotel_id', None)\n",
        "\n",
        "                # Retry fetching hotel_id if it's None\n",
        "                while hotel_id is None and retry_attempts > 0:\n",
        "                    print(f\"🔄 Retrying to fetch hotel_id for hotel in {destination}... ({4 - retry_attempts}/3)\")\n",
        "                    time.sleep(wait_time)  # Wait before retrying\n",
        "                    hotel_id = property_info.get('hotel_id', None)  # Re-fetch hotel_id\n",
        "                    retry_attempts -= 1\n",
        "\n",
        "                # If still no valid hotel_id, use global_hotel_id as a fallback\n",
        "                if hotel_id is None:\n",
        "                    print(f\"❌ API did not return a hotel_id for this hotel in {destination}. Assigning fallback ID: {global_hotel_id}\")\n",
        "                    hotel_id = f\"fallback_{global_hotel_id}\"  # Assign a unique fallback ID\n",
        "                    global_hotel_id += 1  # Increment global counter for next fallback ID\n",
        "\n",
        "                print(f\"✅ Using hotel_id: {hotel_id} for {property_info.get('name', 'Unknown Hotel')}\")\n",
        "\n",
        "                hotel_name = property_info.get('name', 'N/A')\n",
        "                rating = property_info.get('accuratePropertyClass', 'N/A')\n",
        "                review_score = property_info.get('reviewScore', 'N/A')\n",
        "                review_count = property_info.get('reviewCount', 'N/A')\n",
        "\n",
        "                # Price breakdown\n",
        "                price_info = property_info.get('priceBreakdown', {})\n",
        "                price = price_info.get('grossPrice', {}).get('value', 'N/A')\n",
        "                currency = price_info.get('grossPrice', {}).get('currency', currency)\n",
        "\n",
        "                # Hotel images\n",
        "                images = property_info.get('photoUrls', [])\n",
        "                first_image = images[0] if images else \"No Image Available\"\n",
        "\n",
        "                # Print hotel details\n",
        "                print(f\"🏨 **{hotel_name}**\")\n",
        "                print(f\"🆔 ID: {hotel_id}\")\n",
        "                print(f\"⭐ Rating: {rating} Stars | 🏆 Review Score: {review_score} ({review_count} reviews)\")\n",
        "                print(f\"💰 Price per Night: {price} {currency}\")\n",
        "                print(f\"📸 Image: {first_image}\")\n",
        "                print(\"=\"*60)\n",
        "\n",
        "                # ✅ **Store the hotel in the database**\n",
        "                if not db.collection(\"hotels\").has(hotel_id):\n",
        "                  sanitized_key = hashlib.md5(hotel_name.encode()).hexdigest()  # Generate a valid key\n",
        "                  db.collection(\"hotels\").insert({\n",
        "                      \"_key\": sanitized_key,\n",
        "                      \"name\": hotel_name,\n",
        "                      \"destination\": destination,\n",
        "                      \"rating\": rating,\n",
        "                      \"review_score\": review_score,\n",
        "                      \"review_count\": review_count,\n",
        "                      \"price\": price,\n",
        "                      \"currency\": currency,\n",
        "                      \"image\": first_image\n",
        "                  })\n",
        "                  print(f\"🏨 Hotel '{hotel_name}' added to database with key: {sanitized_key}\")\n",
        "\n",
        "        else:\n",
        "            print(f\"❌ Error: 'hotels' key not found for {destination}. Check API response structure.\")\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"❌ Error decoding JSON response for {destination}:\", e)\n"
      ],
      "metadata": {
        "id": "Hm23XW90QmSy"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_attraction_location(destination):\n",
        "    conn = http.client.HTTPSConnection(rapidapi_host)\n",
        "    headers = {\n",
        "        'x-rapidapi-key': rapidapi_key,\n",
        "        'x-rapidapi-host': rapidapi_host\n",
        "    }\n",
        "    request_url = f\"/api/v1/attraction/searchLocation?query={destination}&languagecode=en-us\"\n",
        "    conn.request(\"GET\", request_url, headers=headers)\n",
        "    res = conn.getresponse()\n",
        "    data = res.read()\n",
        "\n",
        "    try:\n",
        "        attractions_data = json.loads(data.decode(\"utf-8\"))\n",
        "        if 'data' in attractions_data and 'products' in attractions_data['data']:\n",
        "            print(f\"\\n🎡 **Attractions in {destination}:**\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            for attraction in attractions_data['data']['products']:\n",
        "                title = attraction.get('title', 'N/A')\n",
        "                product_id = attraction.get('productId', 'N/A')\n",
        "                category = attraction.get('taxonomySlug', 'N/A').replace('-', ' ').title()\n",
        "\n",
        "                print(f\"🔹 **{title}**\")\n",
        "                print(f\"   🔗 Product ID: {product_id}\")\n",
        "                print(f\"   🌍 Category: {category}\")\n",
        "                print(\"-\"*60)\n",
        "\n",
        "                # ✅ **Store the attraction in the database**\n",
        "                if not db.collection(\"attractions\").has(product_id):\n",
        "                  sanitized_key = hashlib.md5(title.encode()).hexdigest()  # Generate a valid key\n",
        "                  db.collection(\"attractions\").insert({\n",
        "                      \"_key\": sanitized_key,\n",
        "                      \"name\": title,\n",
        "                      \"destination\": destination,\n",
        "                      \"category\": category\n",
        "                  })\n",
        "                  print(f\"🎡 Attraction '{title}' added to database with key: {sanitized_key}\")\n",
        "\n",
        "        else:\n",
        "            print(f\"❌ No attractions found for {destination}.\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"❌ Error decoding JSON response for {destination}:\", e)"
      ],
      "metadata": {
        "id": "Yr9V1XAXQoie"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_flight_destination_id(city):\n",
        "    conn = http.client.HTTPSConnection(rapidapi_host)\n",
        "    headers = {\n",
        "        'x-rapidapi-key': rapidapi_key,\n",
        "        'x-rapidapi-host': rapidapi_host\n",
        "    }\n",
        "    request_url = f\"/api/v1/flights/searchDestination?query={city}\"\n",
        "    conn.request(\"GET\", request_url, headers=headers)\n",
        "    res = conn.getresponse()\n",
        "    data = res.read()\n",
        "\n",
        "    try:\n",
        "        flight_data = json.loads(data.decode(\"utf-8\"))\n",
        "        if 'data' in flight_data and isinstance(flight_data['data'], list) and len(flight_data['data']) > 0:\n",
        "            best_match = flight_data['data'][0]\n",
        "            flight_id = best_match.get('id', 'N/A')\n",
        "\n",
        "            print(f\"✈️ Flight Destination ID for {city}: {flight_id}\")\n",
        "\n",
        "            # ✅ **Store flight destination in the database**\n",
        "            if not db.collection(\"flight_destinations\").has(flight_id):\n",
        "                db.collection(\"flight_destinations\").insert({\n",
        "                    \"_key\": str(flight_id),\n",
        "                    \"city\": city,\n",
        "                    \"flight_id\": flight_id\n",
        "                })\n",
        "                print(f\"🛫 Flight Destination '{city}' added to database.\")\n",
        "\n",
        "            return flight_id\n",
        "        else:\n",
        "            print(f\"❌ Error: No flight destination found for {city}.\")\n",
        "            return None\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"❌ Error decoding JSON response for {city}:\", e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "6uJeAUPxQqav"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_flight_details(token, currency=\"USD\"):\n",
        "    \"\"\"Fetch detailed flight information using a booking token\"\"\"\n",
        "    conn = http.client.HTTPSConnection(rapidapi_host)\n",
        "    headers = {\n",
        "        'x-rapidapi-key': rapidapi_key,\n",
        "        'x-rapidapi-host': rapidapi_host\n",
        "    }\n",
        "    request_url = f\"/api/v1/flights/getFlightDetails?token={token}&currency_code={currency}\"\n",
        "    conn.request(\"GET\", request_url, headers=headers)\n",
        "    res = conn.getresponse()\n",
        "    data = res.read()\n",
        "\n",
        "    try:\n",
        "        flight_details = json.loads(data.decode(\"utf-8\"))\n",
        "        return flight_details\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"❌ Error decoding JSON response for flight details:\", e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "LgZZY4uLQt6H"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_flights(from_city, to_city, departure_date, return_date, adults=1, children=\"0,17\", sort=\"BEST\", cabin_class=\"ECONOMY\", currency=\"USD\", page_no=1):\n",
        "    \"\"\"Search for flights and retrieve detailed flight info using a token.\"\"\"\n",
        "    from_id = get_flight_destination_id(from_city)\n",
        "    to_id = get_flight_destination_id(to_city)\n",
        "    if not from_id or not to_id:\n",
        "        print(\"❌ Error: Could not retrieve flight destination IDs.\")\n",
        "        return\n",
        "\n",
        "    conn = http.client.HTTPSConnection(rapidapi_host)\n",
        "    headers = {\n",
        "        'x-rapidapi-key': rapidapi_key,\n",
        "        'x-rapidapi-host': rapidapi_host\n",
        "    }\n",
        "\n",
        "    request_url = f\"/api/v1/flights/searchFlights?fromId={from_id}&toId={to_id}&pageNo={page_no}&adults={adults}&children={children}&sort={sort}&cabinClass={cabin_class}&currency_code={currency}&departDate={departure_date}&returnDate={return_date}\"\n",
        "\n",
        "    conn.request(\"GET\", request_url, headers=headers)\n",
        "    res = conn.getresponse()\n",
        "    data = res.read()\n",
        "\n",
        "    try:\n",
        "        flights_data = json.loads(data.decode(\"utf-8\"))\n",
        "        if \"data\" in flights_data and \"flightOffers\" in flights_data[\"data\"]:\n",
        "            flights_list = flights_data[\"data\"][\"flightOffers\"][:5]  # Fetch first 15 flights\n",
        "\n",
        "            print(f\"\\n✈️ **Top 15 Available Flights from {from_city} to {to_city} (Page {page_no}):**\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            for flight in flights_list:\n",
        "                token = flight.get(\"token\", None)\n",
        "                if not token:\n",
        "                    print(\"❌ No booking token found, skipping flight.\")\n",
        "                    continue\n",
        "\n",
        "                flight_details = get_flight_details(token, currency)\n",
        "                if not flight_details or \"data\" not in flight_details:\n",
        "                    print(\"❌ No flight details found, skipping.\")\n",
        "                    continue\n",
        "\n",
        "                detailed_flight = flight_details[\"data\"]\n",
        "\n",
        "                # Extract flight segments\n",
        "                segments = detailed_flight.get(\"segments\", [])\n",
        "                if not segments:\n",
        "                    print(\"❌ No flight segments found, skipping.\")\n",
        "                    continue\n",
        "\n",
        "                first_segment = segments[0]\n",
        "\n",
        "                departure_airport = first_segment.get(\"departureAirport\", {}).get(\"name\", \"Unknown Airport\")\n",
        "                arrival_airport = first_segment.get(\"arrivalAirport\", {}).get(\"name\", \"Unknown Airport\")\n",
        "                departure_time = first_segment.get(\"departureTime\", \"Unknown Time\")\n",
        "                arrival_time = first_segment.get(\"arrivalTime\", \"Unknown Time\")\n",
        "\n",
        "                # Extract airline details\n",
        "                first_leg = first_segment.get(\"legs\", [{}])[0]\n",
        "                flight_number = first_leg.get(\"flightInfo\", {}).get(\"flightNumber\", \"N/A\")\n",
        "                cabin_class = first_leg.get(\"cabinClass\", \"N/A\")\n",
        "                airline_info = first_leg.get(\"carriersData\", [{}])[0]\n",
        "                airline_name = airline_info.get(\"name\", \"Unknown Airline\")\n",
        "                airline_logo = airline_info.get(\"logo\", \"N/A\")\n",
        "\n",
        "                # Extract price\n",
        "                price_info = detailed_flight.get(\"priceBreakdown\", {}).get(\"total\", {})\n",
        "                price = price_info.get(\"units\", \"N/A\")\n",
        "                price_nanos = price_info.get(\"nanos\", 0) / 1e9  # Convert nanos to decimals\n",
        "                price_currency = price_info.get(\"currencyCode\", currency)\n",
        "\n",
        "                print(f\"🛫 **{airline_name} ({flight_number})**\")\n",
        "                print(f\"   ⏳ Departure: {departure_time} from {departure_airport}\")\n",
        "                print(f\"   🛬 Arrival: {arrival_time} at {arrival_airport}\")\n",
        "                print(f\"   🏷️ Cabin Class: {cabin_class}\")\n",
        "                print(f\"   💰 Price: {price + price_nanos:.2f} {price_currency}\")\n",
        "                print(f\"   ✈️ Airline Logo: {airline_logo}\")\n",
        "                print(\"-\" * 60)\n",
        "\n",
        "                # ✅ **Store the flight in the database**\n",
        "                flight_key = f\"{from_city}_{to_city}_{flight_number}\"\n",
        "                if not db.collection(\"flights\").has(flight_key):\n",
        "                    db.collection(\"flights\").insert({\n",
        "                        \"_key\": flight_key,\n",
        "                        \"from_city\": from_city,\n",
        "                        \"to_city\": to_city,\n",
        "                        \"flight_number\": flight_number,\n",
        "                        \"departure_airport\": departure_airport,\n",
        "                        \"arrival_airport\": arrival_airport,\n",
        "                        \"departure_time\": departure_time,\n",
        "                        \"arrival_time\": arrival_time,\n",
        "                        \"airline_name\": airline_name,\n",
        "                        \"airline_logo\": airline_logo,\n",
        "                        \"cabin_class\": cabin_class,\n",
        "                        \"price\": price + price_nanos,\n",
        "                        \"currency\": price_currency\n",
        "                    })\n",
        "                    print(f\"✅ Flight {flight_number} from {from_city} to {to_city} added to database.\")\n",
        "\n",
        "        else:\n",
        "            print(f\"❌ No flights found from {from_city} to {to_city} on page {page_no}.\")\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"❌ Error decoding JSON response for flights from {from_city} to {to_city}:\", e)\n"
      ],
      "metadata": {
        "id": "iG6gpQkoQvyb"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "travel_graph = nx.Graph()\n",
        "\n",
        "def load_cities(db):\n",
        "    \"\"\"Load destinations (cities) into the graph.\"\"\"\n",
        "    try:\n",
        "        destinations = [doc[\"name\"] for doc in db.collection(\"destinations\").all()]\n",
        "        flight_destinations = [doc[\"city\"] for doc in db.collection(\"flight_destinations\").all()]\n",
        "\n",
        "        all_cities = set(destinations + flight_destinations)  # Merge both collections\n",
        "\n",
        "        for city in all_cities:\n",
        "            # Ensure city is stored in ArangoDB\n",
        "            if not db.collection(\"cities\").has(city):\n",
        "                db.collection(\"cities\").insert({\"_key\": city, \"name\": city})\n",
        "                print(f\"✅ Added city '{city}' to database.\")\n",
        "\n",
        "            travel_graph.add_node(city, type=\"city\")\n",
        "\n",
        "        print(f\"✅ Loaded {len(all_cities)} destinations (cities)\")\n",
        "    except Exception as e:\n",
        "        print(\"❌ Error fetching cities:\", str(e))\n",
        "\n",
        "\n",
        "def load_attractions(db):\n",
        "    \"\"\"Load attractions into the graph and link them to their respective destinations.\"\"\"\n",
        "    try:\n",
        "        attractions = db.collection(\"attractions\").all()\n",
        "        for doc in attractions:\n",
        "            attraction_name = doc[\"name\"]\n",
        "            city_name = doc[\"destination\"]  # Changed from 'city' to 'destination'\n",
        "            travel_graph.add_node(attraction_name, type=\"attraction\")\n",
        "            travel_graph.add_edge(city_name, attraction_name, type=\"attraction\")\n",
        "        print(f\"✅ Loaded {len(attractions)} attractions\")\n",
        "    except Exception as e:\n",
        "        print(\"❌ Error fetching attractions:\", str(e))\n",
        "\n",
        "def load_hotels(db):\n",
        "    \"\"\"Load hotels into the graph and link them to their respective destinations.\"\"\"\n",
        "    try:\n",
        "        hotels = db.collection(\"hotels\").all()\n",
        "        for doc in hotels:\n",
        "            hotel_name = doc[\"name\"]\n",
        "            city_name = doc[\"destination\"]  # Changed from 'city' to 'destination'\n",
        "            travel_graph.add_node(hotel_name, type=\"hotel\")\n",
        "            travel_graph.add_edge(city_name, hotel_name, type=\"hotel\")\n",
        "        print(f\"✅ Loaded {len(hotels)} hotels\")\n",
        "    except Exception as e:\n",
        "        print(\"❌ Error fetching hotels:\", str(e))\n",
        "\n",
        "def load_flights(db):\n",
        "    \"\"\"Load flights as edges between cities.\"\"\"\n",
        "    try:\n",
        "        flights = db.collection(\"flights\").all()\n",
        "        for doc in flights:\n",
        "            if \"from_city\" not in doc or \"to_city\" not in doc:\n",
        "                print(f\"❌ Skipping invalid flight entry: {doc}\")\n",
        "                continue  # Skip incorrect flight entries\n",
        "\n",
        "            from_city = doc[\"from_city\"]\n",
        "            to_city = doc[\"to_city\"]\n",
        "            flight_number = doc[\"flight_number\"]\n",
        "            price = doc.get(\"price\", None)\n",
        "\n",
        "            # Ensure nodes exist before adding an edge\n",
        "            if from_city not in travel_graph:\n",
        "                travel_graph.add_node(from_city, type=\"city\")\n",
        "            if to_city not in travel_graph:\n",
        "                travel_graph.add_node(to_city, type=\"city\")\n",
        "\n",
        "            # Assign weight based on price\n",
        "            edge_weight = float(price) if price else 1\n",
        "            travel_graph.add_edge(from_city, to_city, type=\"flight\", flight_number=flight_number, price=price, weight=edge_weight)\n",
        "\n",
        "        print(f\"✅ Loaded flights with weights\")\n",
        "    except Exception as e:\n",
        "        print(\"❌ Error fetching flights:\", str(e))\n",
        "\n",
        "\n",
        "def display_graph():\n",
        "    \"\"\"Visualize the travel graph.\"\"\"\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    travel_graph = nx.Graph()\n",
        "    pos = nx.spring_layout(travel_graph)\n",
        "\n",
        "    # Classify nodes by type\n",
        "    city_nodes = [node for node, attr in travel_graph.nodes(data=True) if attr[\"type\"] == \"city\"]\n",
        "    attraction_nodes = [node for node, attr in travel_graph.nodes(data=True) if attr[\"type\"] == \"attraction\"]\n",
        "    hotel_nodes = [node for node, attr in travel_graph.nodes(data=True) if attr[\"type\"] == \"hotel\"]\n",
        "\n",
        "    # Draw Nodes\n",
        "    nx.draw_networkx_nodes(travel_graph, pos, nodelist=city_nodes, node_color=\"blue\", node_size=800, label=\"Cities\")\n",
        "    nx.draw_networkx_nodes(travel_graph, pos, nodelist=attraction_nodes, node_color=\"green\", node_size=500, label=\"Attractions\")\n",
        "    nx.draw_networkx_nodes(travel_graph, pos, nodelist=hotel_nodes, node_color=\"red\", node_size=500, label=\"Hotels\")\n",
        "\n",
        "    # Draw Edges\n",
        "    nx.draw_networkx_edges(travel_graph, pos, edgelist=[(u, v) for u, v, d in travel_graph.edges(data=True) if d[\"type\"] == \"flight\"], edge_color=\"black\", style=\"dotted\", label=\"Flights\")\n",
        "    nx.draw_networkx_edges(travel_graph, pos, edgelist=[(u, v) for u, v, d in travel_graph.edges(data=True) if d[\"type\"] == \"attraction\"], edge_color=\"green\", label=\"Attractions\")\n",
        "    nx.draw_networkx_edges(travel_graph, pos, edgelist=[(u, v) for u, v, d in travel_graph.edges(data=True) if d[\"type\"] == \"hotel\"], edge_color=\"red\", label=\"Hotels\")\n",
        "\n",
        "    # Labels\n",
        "    nx.draw_networkx_labels(travel_graph, pos, font_size=10, font_color=\"black\")\n",
        "\n",
        "    plt.legend()\n",
        "    plt.title(\"Travel Graph\")\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "-cPeuqdxTd7H"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_arango_graph(db):\n",
        "    \"\"\"Ensure 'TravelGraph' exists with correct edge definitions.\"\"\"\n",
        "    if db.has_graph(\"TravelGraph\"):\n",
        "        print(\"📌 'TravelGraph' already exists in ArangoDB.\")\n",
        "        return db.graph(\"TravelGraph\")  # Return existing graph\n",
        "\n",
        "    print(\"📌 Creating 'TravelGraph' with proper edge definitions...\")\n",
        "\n",
        "    # Define the graph with edge collections\n",
        "    graph = db.create_graph(\n",
        "        \"TravelGraph\",\n",
        "        edge_definitions=[\n",
        "            {\n",
        "                \"edge_collection\": \"flights\",\n",
        "                \"from_vertex_collections\": [\"cities\"],\n",
        "                \"to_vertex_collections\": [\"cities\"]\n",
        "            },\n",
        "            {\n",
        "                \"edge_collection\": \"hotel_links\",\n",
        "                \"from_vertex_collections\": [\"cities\"],\n",
        "                \"to_vertex_collections\": [\"hotels\"]\n",
        "            },\n",
        "            {\n",
        "                \"edge_collection\": \"attraction_links\",\n",
        "                \"from_vertex_collections\": [\"cities\"],\n",
        "                \"to_vertex_collections\": [\"attractions\"]\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(\"✅ 'TravelGraph' created successfully!\")\n",
        "    return graph\n",
        "\n",
        "# ✅ Create the ArangoDB graph before loading data\n",
        "arango_graph = create_arango_graph(db)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "timJQxUUQxfo",
        "outputId": "b77494fb-6de8-48b2-8955-12c4573c7935"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 'TravelGraph' already exists in ArangoDB.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "import networkx as nx\n",
        "from arango import ArangoClient\n",
        "\n",
        "def load_networkx_to_arangodb(db, travel_graph):\n",
        "    \"\"\"Load the NetworkX Graph into ArangoDB with properly formatted edges and node validation.\"\"\"\n",
        "    if db is None:\n",
        "        print(\"❌ Error: Database not initialized.\")\n",
        "        return None\n",
        "\n",
        "    print(\"🔄 Loading NetworkX graph into ArangoDB...\")\n",
        "\n",
        "    try:\n",
        "        # Ensure the 'TravelGraph' exists in ArangoDB\n",
        "        arango_graph = create_arango_graph(db)\n",
        "\n",
        "        edges_to_insert = []  # Store edges before inserting them\n",
        "\n",
        "        for u, v, data in list(travel_graph.edges(data=True)):  # Convert edges to list before iterating\n",
        "            edge_type = data.get(\"type\", \"unknown\")\n",
        "            weight = data.get(\"weight\", 1)  # Default weight if not specified\n",
        "\n",
        "            # **Determine the correct edge collection**\n",
        "            if edge_type == \"flight\":\n",
        "                edge_collection = \"flights\"\n",
        "                from_collection = \"cities\"\n",
        "                to_collection = \"cities\"\n",
        "            elif edge_type == \"hotel\":\n",
        "                edge_collection = \"hotel_links\"\n",
        "                from_collection = \"cities\"\n",
        "                to_collection = \"hotels\"\n",
        "            elif edge_type == \"attraction\":\n",
        "                edge_collection = \"attraction_links\"\n",
        "                from_collection = \"cities\"\n",
        "                to_collection = \"attractions\"\n",
        "            else:\n",
        "                print(f\"⚠️ Unknown edge type: {edge_type} between {u} and {v}, skipping...\")\n",
        "                continue\n",
        "\n",
        "            # **Fetch correct `_key` for attractions and hotels before inserting edges**\n",
        "            if edge_type == \"hotel\":\n",
        "                hotel_doc = list(db.collection(\"hotels\").find({\"name\": v}))  # Convert cursor to list\n",
        "                if hotel_doc:\n",
        "                    v = hotel_doc[0][\"_key\"]  # Get stored _key\n",
        "                else:\n",
        "                    print(f\"❌ Skipping edge! Hotel '{v}' not found in database.\")\n",
        "                    continue\n",
        "\n",
        "            elif edge_type == \"attraction\":\n",
        "                attraction_doc = list(db.collection(\"attractions\").find({\"name\": v}))  # Convert cursor to list\n",
        "                if attraction_doc:\n",
        "                    v = attraction_doc[0][\"_key\"]  # Get stored _key\n",
        "                else:\n",
        "                    print(f\"❌ Skipping edge! Attraction '{v}' not found in database.\")\n",
        "                    continue\n",
        "\n",
        "            # **Ensure nodes exist before adding the edge**\n",
        "            if not db.collection(from_collection).get(u):\n",
        "                print(f\"❌ Skipping edge! Node '{u}' not found in collection '{from_collection}'.\")\n",
        "                continue\n",
        "\n",
        "            if not db.collection(to_collection).get(v):\n",
        "                print(f\"❌ Skipping edge! Node '{v}' not found in collection '{to_collection}'.\")\n",
        "                continue\n",
        "\n",
        "            # **Ensure Nodes Exist in NetworkX Graph**\n",
        "            if u not in travel_graph:\n",
        "                travel_graph.add_node(u, type=from_collection)\n",
        "            if v not in travel_graph:\n",
        "                travel_graph.add_node(v, type=to_collection)\n",
        "\n",
        "            # **Generate a unique edge key**\n",
        "            edge_key = hashlib.md5(f\"{u}_{v}\".encode()).hexdigest()  # Unique hash for edge key\n",
        "\n",
        "            # **Ensure correct format for `_from` and `_to`**\n",
        "            edge_data = {\n",
        "                \"_key\": edge_key,\n",
        "                \"_from\": f\"{from_collection}/{u}\",\n",
        "                \"_to\": f\"{to_collection}/{v}\",\n",
        "                \"type\": edge_type,\n",
        "                \"weight\": weight\n",
        "            }\n",
        "\n",
        "            # Store edges before inserting\n",
        "            edges_to_insert.append((edge_collection, edge_key, edge_data))\n",
        "\n",
        "        # **Insert edges in batch**\n",
        "        for edge_collection, edge_key, edge_data in edges_to_insert:\n",
        "            existing_edge = db.collection(edge_collection).get(edge_key)\n",
        "            if not existing_edge:\n",
        "                db.collection(edge_collection).insert(edge_data)\n",
        "                print(f\"✅ Edge {edge_data['type']} from {edge_data['_from']} to {edge_data['_to']} added.\")\n",
        "            else:\n",
        "                print(f\"📌 Edge {edge_data['type']} from {edge_data['_from']} to {edge_data['_to']} already exists.\")\n",
        "\n",
        "        print(\"✅ All edges correctly loaded into ArangoDB!\")\n",
        "\n",
        "        # ✅ **Return the NetworkX Graph with nodes and edges**\n",
        "        return travel_graph\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading NetworkX graph into ArangoDB: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "a4Y-L8IQTqO8"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.graphs import ArangoGraph\n",
        "\n",
        "# Initialize ArangoGraph\n",
        "arango_graph1 = ArangoGraph(db)"
      ],
      "metadata": {
        "id": "QSOPR7DnRAVz"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain-openai\n",
        "!pip install --upgrade langchain langchain-community langchain-openai langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shqvUEAURDfQ",
        "outputId": "25ce1f26-37e4-45da-ee95-da40659575a6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.7)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.39 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.41)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.65.4)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (0.3.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (2.10.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.39->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.39->langchain-openai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.39->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.39->langchain-openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.39->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.39->langchain-openai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.3.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.20)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.7)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.3.5)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.41)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.8.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.65.4)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.16)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.1)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.53)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import openai\n",
        "import langchain_community.chat_models\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "#from langchain.chains import RetrievalQA\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "\n",
        "\n",
        "\n",
        "importlib.reload(langchain_community.chat_models)\n",
        "\n",
        "\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "\n",
        "openai.api_key = openai_api_key\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.1, openai_api_key=openai.api_key)\n",
        "print(llm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzxkfmrgRFcr",
        "outputId": "58d5dadd-71a7-4b1b-b07e-c816426d666d"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "client=<openai.resources.chat.completions.Completions object at 0x788c19350350> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x788c1060f710> temperature=0.1 model_kwargs={} openai_api_key='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' openai_proxy=''\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import importlib\n",
        "import langchain_community.chat_models\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain.tools import tool\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
        "\n",
        "# 🔄 Reload LangChain to avoid any version conflicts\n",
        "importlib.reload(langchain_community.chat_models)\n",
        "\n",
        "# ✅ ArangoDB Connection\n",
        "# (Assuming `db` is already connected)\n",
        "\n",
        "arango_graph = ArangoGraphQAChain.from_llm(\n",
        "    llm=ChatOpenAI(temperature=0, model_name=\"gpt-4o\", openai_api_key=openai.api_key),\n",
        "    graph=arango_graph1,  # Your ArangoDB connection\n",
        "    verbose=True,\n",
        "    allow_dangerous_requests = True\n",
        ")\n",
        "\n",
        "\n",
        "# ✅ Initialize LLM\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0.1, openai_api_key=openai_api_key)\n"
      ],
      "metadata": {
        "id": "kXRTjpV5RN8e"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 User Preferences Storage\n",
        "user_preferences = {}\n",
        "\n",
        "import json\n",
        "import re\n",
        "from langchain.tools import tool\n",
        "\n",
        "@tool\n",
        "def set_user_preference(query: str):\n",
        "    \"\"\"Extracts and stores user travel preferences from a natural language input.\"\"\"\n",
        "\n",
        "    structured_prompt = f\"\"\"\n",
        "    Extract structured travel preferences from the following user input:\n",
        "\n",
        "    ---\n",
        "    \"{query}\"\n",
        "    ---\n",
        "\n",
        "    Return a JSON object with **ONLY** the following fields:\n",
        "    - `destination` (e.g., \"Dubai\")\n",
        "    - `origin` (e.g., \"Mumbai\")\n",
        "    - `travelers` (must contain `adults` and `children`)\n",
        "    - `travel_dates` (must contain `start` and `end` in YYYY-MM-DD format)\n",
        "\n",
        "    Example response:\n",
        "    ```json\n",
        "    {{\n",
        "      \"destination\": \"Dubai\",\n",
        "      \"origin\": \"Mumbai\",\n",
        "      \"travelers\": {{\n",
        "        \"adults\": 2,\n",
        "        \"children\": 1\n",
        "      }},\n",
        "      \"travel_dates\": {{\n",
        "        \"start\": \"2025-03-15\",\n",
        "        \"end\": \"2025-03-22\"\n",
        "      }}\n",
        "    }}\n",
        "    ```\n",
        "\n",
        "    **DO NOT** include explanations or additional text—only return the JSON.\n",
        "    \"\"\"\n",
        "\n",
        "    # ✅ Call LLM to extract structured preferences\n",
        "    response = llm.invoke(structured_prompt)\n",
        "\n",
        "    try:\n",
        "        # ✅ Extract JSON using regex if the LLM returns text around the JSON\n",
        "        json_match = re.search(r\"\\{.*\\}\", response.content, re.DOTALL)\n",
        "        if json_match:\n",
        "            extracted_json = json_match.group(0)\n",
        "            extracted_data = json.loads(extracted_json)  # Convert to Python dictionary\n",
        "            user_preferences.update(extracted_data)\n",
        "            return f\"✅ Preferences updated: {extracted_data}\"\n",
        "        else:\n",
        "            return \"❌ JSON extraction failed. Try providing details in a structured format.\"\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        return f\"❌ Error decoding JSON: {str(e)}. Please try rephrasing your input.\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_user_preferences(query: str):\n",
        "    \"\"\"Retrieve stored user travel preferences.\"\"\"\n",
        "    return f\"📝 Your preferences: {user_preferences}\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def find_flights(query: str):\n",
        "    \"\"\"Finds the best available flights for the user's travel.\"\"\"\n",
        "\n",
        "    # Extract structured preferences\n",
        "    destination = user_preferences.get(\"destination\", \"\")\n",
        "    origin = user_preferences.get(\"origin\", \"\")\n",
        "    start_date = user_preferences.get(\"travel_dates\", {}).get(\"start\", \"\")\n",
        "    end_date = user_preferences.get(\"travel_dates\", {}).get(\"end\", \"\")\n",
        "\n",
        "    if not destination or not origin or not start_date:\n",
        "        return \"❌ Please provide the origin, destination, and departure date.\"\n",
        "\n",
        "    # Adjust AQL query to find flights **across multiple days** (e.g., one day before & after)\n",
        "    aql_query = f\"\"\"\n",
        "    WITH flights\n",
        "    FOR flight IN flights\n",
        "      FILTER flight.from_city == \"{origin}\"\n",
        "      FILTER flight.to_city == \"{destination}\"\n",
        "      FILTER flight.departure_time >= \"{start_date}T00:00:00\"\n",
        "      FILTER flight.departure_time <= \"{start_date}T23:59:59\"\n",
        "      RETURN flight\n",
        "    \"\"\"\n",
        "\n",
        "    result = arango_graph.invoke(aql_query)\n",
        "\n",
        "    if not result[\"result\"]:\n",
        "        return f\"❌ No flights found from {origin} to {destination} on {start_date}. Try adjusting your dates.\"\n",
        "\n",
        "    return f\"✅ Available flights: {result['result']}\"\n",
        "\n",
        "\n",
        "\n",
        "@tool\n",
        "def find_hotels(query: str):\n",
        "    \"\"\"Finds the best hotels at a given destination.\"\"\"\n",
        "    return arango_graph.invoke(f\"Find hotels for {query}\")\n",
        "\n",
        "\n",
        "@tool\n",
        "def find_attractions(query: str):\n",
        "    \"\"\"Finds popular attractions at a given destination.\"\"\"\n",
        "    return arango_graph.invoke(f\"Find attractions for {query}\")\n",
        "\n",
        "\n",
        "@tool\n",
        "def summarize_trip(query: str):\n",
        "    \"\"\"Summarizes the trip based on stored preferences.\"\"\"\n",
        "    destination = user_preferences.get(\"destination\", \"Unknown\")\n",
        "\n",
        "    if destination == \"Unknown\":\n",
        "        return \"❌ Please set your travel destination first.\"\n",
        "\n",
        "    flights = find_flights(destination)\n",
        "    hotels = find_hotels(destination)\n",
        "    attractions = find_attractions(destination)\n",
        "\n",
        "    return f\"\"\"🎉 **Your Travel Summary for {destination}:** 🎉\n",
        "\n",
        "✈️ **Flights:** {flights}\n",
        "🏨 **Hotels:** {hotels}\n",
        "🎡 **Attractions:** {attractions}\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "9wWPej_iRZKH"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Define Tools for the AI Agent\n",
        "tools = [set_user_preference, get_user_preferences, find_flights, find_hotels, find_attractions, summarize_trip]\n",
        "\n",
        "# ✅ Conversation Memory (Remembers User Inputs)\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "\n",
        "# ✅ Define the AI Travel Agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    memory=memory,\n",
        "    agent=AgentType.OPENAI_FUNCTIONS,  # OpenAI-powered function calls\n",
        "    verbose=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "c47r42umRchP"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SV5rxMobRgys",
        "outputId": "44ad67fc-54d7-486e-abdf-f79621db94cf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.65.4)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.20.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.7.2 (from gradio)\n",
            "  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.9.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.20.0-py3-none-any.whl (62.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.2-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.11 ffmpy-0.5.0 gradio-5.20.0 gradio-client-1.7.2 groovy-0.1.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.9 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.0 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "# ✅ Connect to ArangoDB\n",
        "arango_client = ArangoClient(hosts=\"https://c4c335acccb7.arangodb.cloud:8529\")\n",
        "db = arango_client.db(\"Langchain\", arango_username, arango_password, verify=True)\n",
        "\n",
        "# ✅ Initialize OpenAI Client\n",
        "client = openai.OpenAI(api_key=openai_api_key)\n",
        "\n",
        "# ✅ Store user inputs dynamically\n",
        "user_preferences = {\n",
        "    \"origin\": None,\n",
        "    \"destination\": None,\n",
        "    \"travel_dates\": {\"start\": None, \"end\": None},\n",
        "    \"travelers\": {\"adults\": None, \"children\": None}\n",
        "}\n",
        "\n",
        "# ✅ Context memory for chat history\n",
        "context = [\n",
        "    {'role': 'system', 'content': \"\"\"\n",
        "        You are TravelBot, an automated travel assistant. You collect:\n",
        "        - Destination\n",
        "        - Travel Dates\n",
        "        - Number of Travelers\n",
        "        - Budget\n",
        "        - Attractions\n",
        "\n",
        "        Once all details are gathered, you **fetch real flights and hotels** from the database.\n",
        "    \"\"\"}\n",
        "]\n",
        "\n",
        "# ✅ Function to fetch flights from ArangoDB\n",
        "def get_flights(from_city, to_city, departure_date):\n",
        "    \"\"\"Fetches available flights from ArangoDB.\"\"\"\n",
        "    aql_query = f\"\"\"\n",
        "    WITH flights\n",
        "    FOR flight IN flights\n",
        "      FILTER flight.from_city == \"{from_city}\"\n",
        "      FILTER flight.to_city == \"{to_city}\"\n",
        "      FILTER flight.departure_time >= \"{departure_date}T00:00:00\"\n",
        "      FILTER flight.departure_time <= \"{departure_date}T23:59:59\"\n",
        "      RETURN flight\n",
        "    \"\"\"\n",
        "    result = db.aql.execute(aql_query)\n",
        "    flights = list(result)\n",
        "    return flights if flights else \"No flights found.\"\n",
        "\n",
        "# ✅ Function to fetch hotels from ArangoDB\n",
        "def get_hotels(destination):\n",
        "    \"\"\"Fetches available hotels in the destination from ArangoDB.\"\"\"\n",
        "    aql_query = f\"\"\"\n",
        "    WITH hotels\n",
        "    FOR hotel IN hotels\n",
        "      FILTER hotel.destination == \"{destination}\"\n",
        "      RETURN hotel\n",
        "    \"\"\"\n",
        "    result = db.aql.execute(aql_query)\n",
        "    hotels = list(result)\n",
        "    return hotels if hotels else \"No hotels found.\"\n",
        "\n",
        "\n",
        "# ✅ Chatbot logic: Collects details and fetches real-time data\n",
        "def chatbot_response(user_input):\n",
        "    global user_preferences\n",
        "    global context\n",
        "\n",
        "    context.append({'role': 'user', 'content': user_input})\n",
        "\n",
        "     # ✅ OpenAI GPT-4o Call for Response\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=context,\n",
        "            temperature=0.2\n",
        "        )\n",
        "\n",
        "        bot_reply = response.choices[0].message.content\n",
        "        context.append({'role': 'assistant', 'content': bot_reply})  # Store bot response\n",
        "\n",
        "        # ✅ Extracting User Details Dynamically\n",
        "        user_details = {msg['content'] for msg in context if msg['role'] == 'user'}\n",
        "\n",
        "        # ✅ Initialize variables to avoid referencing before assignment\n",
        "        destination, from_city, departure_date = None, None, None\n",
        "\n",
        "        if any(kw in user_input.lower() for kw in [\"travel to\", \"from\", \"on\"]):\n",
        "            destination = next((msg.split(\"to\")[-1].strip() for msg in user_details if \"to\" in msg), None)\n",
        "            from_city = next((msg.split(\"from\")[-1].strip() for msg in user_details if \"from\" in msg), None)\n",
        "            departure_date = next((msg.split(\"on\")[-1].strip() for msg in user_details if \"on\" in msg), None)\n",
        "\n",
        "        # ✅ Ensure variables are assigned before using them\n",
        "        if destination and from_city and departure_date:\n",
        "            user_preferences[\"destination\"] = destination\n",
        "            user_preferences[\"origin\"] = from_city\n",
        "            user_preferences[\"travel_dates\"][\"start\"] = departure_date\n",
        "            return f\"Got it! You're traveling from {from_city} to {destination} on {departure_date}. How many adults and children are traveling?\"\n",
        "\n",
        "        # Step 2: Trigger API Calls Once All Details Are Collected\n",
        "        if all(user_preferences.values()) and all(user_preferences[\"travel_dates\"].values()) and all(user_preferences[\"travelers\"].values()):\n",
        "            from_city = user_preferences[\"origin\"]\n",
        "            to_city = user_preferences[\"destination\"]\n",
        "            start_date = user_preferences[\"travel_dates\"][\"start\"]\n",
        "            end_date = user_preferences[\"travel_dates\"][\"end\"]\n",
        "\n",
        "            flights = search_flights(from_city, to_city, start_date, end_date)\n",
        "            hotels = get_hotels_in_destination(to_city, start_date, end_date)\n",
        "            attractions = get_attraction_location(to_city)\n",
        "\n",
        "            # Initialize the database\n",
        "            db = setup_arangodb()\n",
        "\n",
        "            # Pass db to the functions\n",
        "            load_cities(db)\n",
        "            load_attractions(db)\n",
        "            load_hotels(db)\n",
        "            load_flights(db)\n",
        "\n",
        "            # ✅ **Display the travel graph**\n",
        "            display_graph()\n",
        "\n",
        "            # ✅ Run the function\n",
        "            G_adb = load_networkx_to_arangodb(db, travel_graph)\n",
        "            print(G_adb)\n",
        "\n",
        "            flights = get_flights(from_city, to_city, start_date)\n",
        "            hotels = get_hotels(to_city)\n",
        "\n",
        "            summary = f\"\"\"\n",
        "            ✈️ **Available Flights:** {flights}\n",
        "            🏨 **Hotels in {to_city}:** {hotels}\n",
        "            \"\"\"\n",
        "\n",
        "            # Format the response\n",
        "            response = f\"\"\"\n",
        "            🎉 **Your Travel Itinerary**\n",
        "            ✈️ **Flights from {from_city} to {to_city}:**\n",
        "            {flights}\n",
        "\n",
        "            🏨 **Hotels in {to_city}:**\n",
        "            {hotels}\n",
        "\n",
        "            🎡 **Attractions in {to_city}:**\n",
        "            {attractions}\n",
        "\n",
        "            Safe travels! Let me know if you need any modifications.\n",
        "            \"\"\"\n",
        "\n",
        "            # Reset user preferences after providing itinerary\n",
        "            user_preferences = { \"origin\": None, \"destination\": None, \"travel_dates\": {\"start\": None, \"end\": None}, \"travelers\": {\"adults\": None, \"children\": None} }\n",
        "\n",
        "            return response\n",
        "        return bot_reply\n",
        "    except Exception as e:\n",
        "        return f\"❌ OpenAI API Error: {str(e)}\"\n",
        "\n",
        "    return \"I didn't quite understand that. Can you please provide the details step by step?\"\n",
        "\n",
        "# ✅ Gradio UI for Interactive Chatbot\n",
        "iface = gr.Interface(\n",
        "    fn=chatbot_response,\n",
        "    inputs=gr.Textbox(placeholder=\"Type your message...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"AI Travel Assistant\",\n",
        "    description=\"Chat with the AI to plan your perfect trip. Start by saying 'I want to travel from Mumbai to Dubai'.\"\n",
        ")\n",
        "\n",
        "# ✅ Launch the Chatbot in Colab\n",
        "iface.launch(share=True, debug = True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "NMt6pDsGRR51",
        "outputId": "6ca9a22b-ae98-4cff-8ca0-702d5fd7405c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://0440c9713b54e71f9d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0440c9713b54e71f9d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7865 <> https://0440c9713b54e71f9d.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import re\n",
        "\n",
        "# ✅ Connect to ArangoDB\n",
        "arango_client = ArangoClient(hosts=\"https://c4c335acccb7.arangodb.cloud:8529\")\n",
        "db = arango_client.db(\"Langchain\", arango_username, arango_password, verify=True)\n",
        "\n",
        "# ✅ Initialize OpenAI Client\n",
        "client = openai.OpenAI(api_key=openai_api_key)\n",
        "\n",
        "# ✅ Store user inputs dynamically\n",
        "user_preferences = {\n",
        "    \"origin\": None,\n",
        "    \"destination\": None,\n",
        "    \"travel_dates\": {\"start\": None, \"end\": None},\n",
        "    \"travelers\": {\"adults\": None, \"children\": None}\n",
        "}\n",
        "\n",
        "# ✅ Context memory for chat history\n",
        "context = [\n",
        "    {'role': 'system', 'content': \"\"\"\n",
        "        You are TravelBot, an automated travel assistant. You collect:\n",
        "        - Destination\n",
        "        - Travel Dates\n",
        "        - Number of Travelers\n",
        "        - Budget\n",
        "        - Attractions\n",
        "\n",
        "        Once all details are gathered, you **fetch real flights and hotels** from the database.\n",
        "    \"\"\"}\n",
        "]\n",
        "\n",
        "# ✅ Function to fetch flights from ArangoDB\n",
        "def get_flights(from_city, to_city, departure_date):\n",
        "    \"\"\"Fetches available flights from ArangoDB.\"\"\"\n",
        "    aql_query = f\"\"\"\n",
        "    WITH flights\n",
        "    FOR flight IN flights\n",
        "      FILTER flight.from_city == \"{from_city}\"\n",
        "      FILTER flight.to_city == \"{to_city}\"\n",
        "      FILTER flight.departure_time >= \"{departure_date}T00:00:00\"\n",
        "      FILTER flight.departure_time <= \"{departure_date}T23:59:59\"\n",
        "      RETURN flight\n",
        "    \"\"\"\n",
        "    result = db.aql.execute(aql_query)\n",
        "    flights = list(result)\n",
        "    return flights if flights else \"No flights found.\"\n",
        "\n",
        "# ✅ Function to fetch hotels from ArangoDB\n",
        "def get_hotels(destination):\n",
        "    \"\"\"Fetches available hotels in the destination from ArangoDB.\"\"\"\n",
        "    aql_query = f\"\"\"\n",
        "    WITH hotels\n",
        "    FOR hotel IN hotels\n",
        "      FILTER hotel.destination == \"{destination}\"\n",
        "      RETURN hotel\n",
        "    \"\"\"\n",
        "    result = db.aql.execute(aql_query)\n",
        "    hotels = list(result)\n",
        "    return hotels if hotels else \"No hotels found.\"\n",
        "\n",
        "def chatbot_response(user_input):\n",
        "    global user_preferences\n",
        "    global context\n",
        "\n",
        "    context.append({'role': 'user', 'content': user_input})\n",
        "\n",
        "    # ✅ OpenAI GPT-4o Call for Response\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=context,\n",
        "            temperature=0.2\n",
        "        )\n",
        "\n",
        "        bot_reply = response.choices[0].message.content\n",
        "        context.append({'role': 'assistant', 'content': bot_reply})  # Store bot response\n",
        "\n",
        "        # ✅ Extracting User Details Dynamically\n",
        "        user_details = {msg['content'] for msg in context if msg['role'] == 'user'}\n",
        "\n",
        "        # ✅ Initialize variables to avoid referencing before assignment\n",
        "        destination, from_city, departure_date = None, None, None\n",
        "\n",
        "        if any(kw in user_input.lower() for kw in [\"travel to\", \"from\", \"on\"]):\n",
        "            destination_match = re.search(r\"to\\s+([\\w\\s]+)\", user_input, re.IGNORECASE)\n",
        "            from_city_match = re.search(r\"from\\s+([\\w\\s]+)\", user_input, re.IGNORECASE)\n",
        "            date_match = re.search(r\"on\\s+(\\d{1,2}\\s\\w+\\s\\d{4})\", user_input, re.IGNORECASE)\n",
        "\n",
        "            destination = destination_match.group(1).strip() if destination_match else None\n",
        "            from_city = from_city_match.group(1).strip() if from_city_match else None\n",
        "            departure_date = date_match.group(1).strip() if date_match else None\n",
        "\n",
        "            travelers_match = re.search(r\"(\\d+)\\s+adults?\", user_input, re.IGNORECASE)\n",
        "            children_match = re.search(r\"(\\d+)\\s+children?\", user_input, re.IGNORECASE)\n",
        "\n",
        "            user_preferences[\"travelers\"][\"adults\"] = int(travelers_match.group(1)) if travelers_match else 1  # Default 1 Adult\n",
        "            user_preferences[\"travelers\"][\"children\"] = int(children_match.group(1)) if children_match else 0  # Default 0 Children\n",
        "\n",
        "\n",
        "        # ✅ Ensure variables are assigned before using them\n",
        "        if destination and from_city and departure_date:\n",
        "            user_preferences[\"destination\"] = destination\n",
        "            user_preferences[\"origin\"] = from_city\n",
        "            user_preferences[\"travel_dates\"][\"start\"] = departure_date\n",
        "            return f\"Got it! You're traveling from {from_city} to {destination} on {departure_date}. How many adults and children are traveling?\"\n",
        "\n",
        "        # ✅ DEBUGGING: Print current user preferences before entering the final if condition\n",
        "        print(\"\\n🔍 DEBUG: Current User Preferences\")\n",
        "        print(user_preferences)\n",
        "\n",
        "        # Step 2: Trigger API Calls Once All Details Are Collected\n",
        "        if (\n",
        "            all(user_preferences.values()) and\n",
        "            all(user_preferences[\"travel_dates\"].values()) and\n",
        "            all(user_preferences[\"travelers\"].values())\n",
        "        ):\n",
        "            print(\"\\n✅ DEBUG: Entering API call block...\")  # Debugging print statement\n",
        "\n",
        "            from_city = user_preferences[\"origin\"]\n",
        "            to_city = user_preferences[\"destination\"]\n",
        "            start_date = user_preferences[\"travel_dates\"][\"start\"]\n",
        "            end_date = user_preferences[\"travel_dates\"][\"end\"]\n",
        "\n",
        "            print(f\"\\n🚀 Fetching travel details for {from_city} → {to_city} from {start_date} to {end_date}\")\n",
        "\n",
        "            # Initialize the database\n",
        "            print(\"\\n🔄 Setting up ArangoDB...\")\n",
        "            db = setup_arangodb()\n",
        "\n",
        "            flights = search_flights(from_city, to_city, start_date, end_date)\n",
        "            hotels = get_hotels_in_destination(to_city, start_date, end_date)\n",
        "            attractions = get_attraction_location(to_city)\n",
        "\n",
        "\n",
        "            # Pass db to the functions\n",
        "            print(\"\\n📌 Loading Travel Data into Graph...\")\n",
        "            load_cities(db)\n",
        "            load_attractions(db)\n",
        "            load_hotels(db)\n",
        "            load_flights(db)\n",
        "\n",
        "            # ✅ **Display the travel graph**\n",
        "            print(\"\\n📊 Displaying Travel Graph...\")\n",
        "            display_graph()\n",
        "\n",
        "            # ✅ Run the function\n",
        "            print(\"\\n🔗 Loading NetworkX Graph into ArangoDB...\")\n",
        "            G_adb = load_networkx_to_arangodb(db, travel_graph)\n",
        "            print(G_adb)\n",
        "\n",
        "            flights = get_flights(from_city, to_city, start_date)\n",
        "            hotels = get_hotels(to_city)\n",
        "\n",
        "            # ✅ Format Response\n",
        "            response = f\"\"\"\n",
        "            🎉 **Your Travel Itinerary**\n",
        "            ✈️ **Flights from {from_city} to {to_city}:**\n",
        "            {flights}\n",
        "\n",
        "            🏨 **Hotels in {to_city}:**\n",
        "            {hotels}\n",
        "\n",
        "            🎡 **Attractions in {to_city}:**\n",
        "            {attractions}\n",
        "\n",
        "            Safe travels! Let me know if you need any modifications.\n",
        "            \"\"\"\n",
        "\n",
        "            # Reset user preferences after providing itinerary\n",
        "            user_preferences = {\n",
        "                \"origin\": None,\n",
        "                \"destination\": None,\n",
        "                \"travel_dates\": {\"start\": None, \"end\": None},\n",
        "                \"travelers\": {\"adults\": None, \"children\": None}\n",
        "            }\n",
        "\n",
        "            return response\n",
        "\n",
        "        # If the final if-condition is not entered, print debug information\n",
        "        print(\"\\n❌ DEBUG: Not all required details are present yet. Waiting for user input...\")\n",
        "        return bot_reply\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ OpenAI API Error: {str(e)}\")  # Debugging error message\n",
        "        return f\"❌ OpenAI API Error: {str(e)}\"\n",
        "\n",
        "    return \"I didn't quite understand that. Can you please provide the details step by step?\"\n",
        "\n",
        "# ✅ Gradio UI for Interactive Chatbot\n",
        "iface = gr.Interface(\n",
        "    fn=chatbot_response,\n",
        "    inputs=gr.Textbox(placeholder=\"Type your message...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"AI Travel Assistant\",\n",
        "    description=\"Chat with the AI to plan your perfect trip. Start by saying 'I want to travel from Mumbai to Dubai'.\"\n",
        ")\n",
        "\n",
        "# ✅ Launch the Chatbot in Colab\n",
        "iface.launch(share=True, debug = True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "owQl2yQaAoPK",
        "outputId": "7844b7f8-8dd5-4ce8-8a9b-6ee0e412e35a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://d7409b2d51739afcc1.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d7409b2d51739afcc1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 DEBUG: Current User Preferences\n",
            "{'origin': None, 'destination': None, 'travel_dates': {'start': None, 'end': None}, 'travelers': {'adults': None, 'children': None}}\n",
            "\n",
            "❌ DEBUG: Not all required details are present yet. Waiting for user input...\n",
            "\n",
            "🔍 DEBUG: Current User Preferences\n",
            "{'origin': None, 'destination': None, 'travel_dates': {'start': None, 'end': None}, 'travelers': {'adults': 1, 'children': 0}}\n",
            "\n",
            "❌ DEBUG: Not all required details are present yet. Waiting for user input...\n",
            "\n",
            "🔍 DEBUG: Current User Preferences\n",
            "{'origin': None, 'destination': None, 'travel_dates': {'start': None, 'end': None}, 'travelers': {'adults': 1, 'children': 0}}\n",
            "\n",
            "❌ DEBUG: Not all required details are present yet. Waiting for user input...\n",
            "\n",
            "🔍 DEBUG: Current User Preferences\n",
            "{'origin': None, 'destination': None, 'travel_dates': {'start': None, 'end': None}, 'travelers': {'adults': 1, 'children': 0}}\n",
            "\n",
            "❌ DEBUG: Not all required details are present yet. Waiting for user input...\n",
            "\n",
            "🔍 DEBUG: Current User Preferences\n",
            "{'origin': None, 'destination': None, 'travel_dates': {'start': None, 'end': None}, 'travelers': {'adults': 1, 'children': 0}}\n",
            "\n",
            "❌ DEBUG: Not all required details are present yet. Waiting for user input...\n",
            "\n",
            "🔍 DEBUG: Current User Preferences\n",
            "{'origin': None, 'destination': None, 'travel_dates': {'start': None, 'end': None}, 'travelers': {'adults': 1, 'children': 0}}\n",
            "\n",
            "❌ DEBUG: Not all required details are present yet. Waiting for user input...\n",
            "\n",
            "🔍 DEBUG: Current User Preferences\n",
            "{'origin': None, 'destination': None, 'travel_dates': {'start': None, 'end': None}, 'travelers': {'adults': 1, 'children': 0}}\n",
            "\n",
            "❌ DEBUG: Not all required details are present yet. Waiting for user input...\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7865 <> https://d7409b2d51739afcc1.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "travel_graph = nx.Graph()\n",
        "\n",
        "def load_cities(db):\n",
        "    \"\"\"Load destinations (cities) into the graph.\"\"\"\n",
        "    try:\n",
        "        destinations = [doc[\"name\"] for doc in db.collection(\"destinations\").all()]\n",
        "        flight_destinations = [doc[\"city\"] for doc in db.collection(\"flight_destinations\").all()]\n",
        "\n",
        "        all_cities = set(destinations + flight_destinations)  # Merge both collections\n",
        "\n",
        "        for city in all_cities:\n",
        "            # Ensure city is stored in ArangoDB\n",
        "            if not db.collection(\"cities\").has(city):\n",
        "                db.collection(\"cities\").insert({\"_key\": city, \"name\": city})\n",
        "                print(f\"✅ Added city '{city}' to database.\")\n",
        "\n",
        "            travel_graph.add_node(city, type=\"city\")\n",
        "\n",
        "        print(f\"✅ Loaded {len(all_cities)} destinations (cities)\")\n",
        "    except Exception as e:\n",
        "        print(\"❌ Error fetching cities:\", str(e))\n",
        "\n",
        "\n",
        "def load_attractions(db):\n",
        "    \"\"\"Load attractions into the graph and link them to their respective destinations.\"\"\"\n",
        "    try:\n",
        "        attractions = db.collection(\"attractions\").all()\n",
        "        for doc in attractions:\n",
        "            attraction_name = doc[\"name\"]\n",
        "            city_name = doc[\"destination\"]  # Changed from 'city' to 'destination'\n",
        "            travel_graph.add_node(attraction_name, type=\"attraction\")\n",
        "            travel_graph.add_edge(city_name, attraction_name, type=\"attraction\")\n",
        "        print(f\"✅ Loaded {len(attractions)} attractions\")\n",
        "    except Exception as e:\n",
        "        print(\"❌ Error fetching attractions:\", str(e))\n",
        "\n",
        "def load_hotels(db):\n",
        "    \"\"\"Load hotels into the graph and link them to their respective destinations.\"\"\"\n",
        "    try:\n",
        "        hotels = db.collection(\"hotels\").all()\n",
        "        for doc in hotels:\n",
        "            hotel_name = doc[\"name\"]\n",
        "            city_name = doc[\"destination\"]  # Changed from 'city' to 'destination'\n",
        "            travel_graph.add_node(hotel_name, type=\"hotel\")\n",
        "            travel_graph.add_edge(city_name, hotel_name, type=\"hotel\")\n",
        "        print(f\"✅ Loaded {len(hotels)} hotels\")\n",
        "    except Exception as e:\n",
        "        print(\"❌ Error fetching hotels:\", str(e))\n",
        "\n",
        "def load_flights(db):\n",
        "    \"\"\"Load flights as edges between cities.\"\"\"\n",
        "    try:\n",
        "        flights = db.collection(\"flights\").all()\n",
        "        for doc in flights:\n",
        "            if \"from_city\" not in doc or \"to_city\" not in doc:\n",
        "                print(f\"❌ Skipping invalid flight entry: {doc}\")\n",
        "                continue  # Skip incorrect flight entries\n",
        "\n",
        "            from_city = doc[\"from_city\"]\n",
        "            to_city = doc[\"to_city\"]\n",
        "            flight_number = doc[\"flight_number\"]\n",
        "            price = doc.get(\"price\", None)\n",
        "\n",
        "            # Ensure nodes exist before adding an edge\n",
        "            if from_city not in travel_graph:\n",
        "                travel_graph.add_node(from_city, type=\"city\")\n",
        "            if to_city not in travel_graph:\n",
        "                travel_graph.add_node(to_city, type=\"city\")\n",
        "\n",
        "            # Assign weight based on price\n",
        "            edge_weight = float(price) if price else 1\n",
        "            travel_graph.add_edge(from_city, to_city, type=\"flight\", flight_number=flight_number, price=price, weight=edge_weight)\n",
        "\n",
        "        print(f\"✅ Loaded flights with weights\")\n",
        "    except Exception as e:\n",
        "        print(\"❌ Error fetching flights:\", str(e))\n",
        "\n",
        "\n",
        "def display_graph():\n",
        "    \"\"\"Visualize the travel graph.\"\"\"\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    pos = nx.spring_layout(travel_graph)\n",
        "\n",
        "    # Classify nodes by type\n",
        "    city_nodes = [node for node, attr in travel_graph.nodes(data=True) if attr[\"type\"] == \"city\"]\n",
        "    attraction_nodes = [node for node, attr in travel_graph.nodes(data=True) if attr[\"type\"] == \"attraction\"]\n",
        "    hotel_nodes = [node for node, attr in travel_graph.nodes(data=True) if attr[\"type\"] == \"hotel\"]\n",
        "\n",
        "    # Draw Nodes\n",
        "    nx.draw_networkx_nodes(travel_graph, pos, nodelist=city_nodes, node_color=\"blue\", node_size=800, label=\"Cities\")\n",
        "    nx.draw_networkx_nodes(travel_graph, pos, nodelist=attraction_nodes, node_color=\"green\", node_size=500, label=\"Attractions\")\n",
        "    nx.draw_networkx_nodes(travel_graph, pos, nodelist=hotel_nodes, node_color=\"red\", node_size=500, label=\"Hotels\")\n",
        "\n",
        "    # Draw Edges\n",
        "    nx.draw_networkx_edges(travel_graph, pos, edgelist=[(u, v) for u, v, d in travel_graph.edges(data=True) if d[\"type\"] == \"flight\"], edge_color=\"black\", style=\"dotted\", label=\"Flights\")\n",
        "    nx.draw_networkx_edges(travel_graph, pos, edgelist=[(u, v) for u, v, d in travel_graph.edges(data=True) if d[\"type\"] == \"attraction\"], edge_color=\"green\", label=\"Attractions\")\n",
        "    nx.draw_networkx_edges(travel_graph, pos, edgelist=[(u, v) for u, v, d in travel_graph.edges(data=True) if d[\"type\"] == \"hotel\"], edge_color=\"red\", label=\"Hotels\")\n",
        "\n",
        "    # Labels\n",
        "    nx.draw_networkx_labels(travel_graph, pos, font_size=10, font_color=\"black\")\n",
        "\n",
        "    plt.legend()\n",
        "    plt.title(\"Travel Graph\")\n",
        "    plt.show()\n",
        "\n",
        "# Initialize the database\n",
        "#db = setup_arangodb()\n",
        "print(db.graphs())\n",
        "print(db.collections())\n",
        "\n",
        "# Pass db to the functions\n",
        "load_cities(db)\n",
        "load_attractions(db)\n",
        "load_hotels(db)\n",
        "load_flights(db)\n",
        "\n",
        "# ✅ **Display the travel graph**\n",
        "display_graph()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "b3xsVBD8Zrrv",
        "outputId": "3b1a2456-8713-41c6-fcaf-95f4905b8aad"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'id': '_graphs/TravelGraph', 'name': 'TravelGraph', 'revision': '_jRyRw9W---', 'orphan_collections': [], 'edge_definitions': [], 'shard_count': None, 'replication_factor': None}]\n",
            "[{'id': '1053', 'name': '_queues', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '1052', 'name': '_aqlfunctions', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '533828', 'name': 'attractions', 'system': False, 'type': 'document', 'status': 'loaded'}, {'id': '1054', 'name': '_jobs', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '533853', 'name': 'flight_destinations', 'system': False, 'type': 'document', 'status': 'loaded'}, {'id': '533833', 'name': 'hotel_links', 'system': False, 'type': 'document', 'status': 'loaded'}, {'id': '1055', 'name': '_apps', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '1056', 'name': '_appbundles', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '1050', 'name': '_graphs', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '533843', 'name': 'cities', 'system': False, 'type': 'document', 'status': 'loaded'}, {'id': '533858', 'name': 'flights', 'system': False, 'type': 'document', 'status': 'loaded'}, {'id': '1057', 'name': '_frontend', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '533838', 'name': 'attraction_links', 'system': False, 'type': 'document', 'status': 'loaded'}, {'id': '533823', 'name': 'hotels', 'system': False, 'type': 'document', 'status': 'loaded'}, {'id': '1051', 'name': '_analyzers', 'system': True, 'type': 'document', 'status': 'loaded'}, {'id': '533848', 'name': 'destinations', 'system': False, 'type': 'document', 'status': 'loaded'}]\n",
            "✅ Loaded 0 destinations (cities)\n",
            "✅ Loaded 0 attractions\n",
            "✅ Loaded 0 hotels\n",
            "✅ Loaded flights with weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-52-a6d62584c55a>:105: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "  plt.legend()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAAKSCAYAAADmsEcMAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGedJREFUeJzt3VuMXmW9x/H/MD3Qw0yHYMcerPTEQcJFqSYQpVSx2JBqYqPt0MZjDBAUJaJGglIamkA8YNtELcZIhV5oiaJQqMjE2GhMjIpoUowW8ZxaSoltpwytTWftC9LZDDN0T+lA+bE/n2Qu3vU+a73Pupp8s9Z6VkvTNE0BAABAqFNO9gQAAADgRAhbAAAAoglbAAAAoglbAAAAoglbAAAAoglbAAAAoglbAAAAoglbAAAAoglbAAAAoglbABgBq1evrpaWlpM9jRP27W9/u1paWuo3v/nNyZ4KAAybsAXgFaWlpWVYf9u2bTvZUz0hP//5z2v58uU1ffr0GjNmTE2aNKkuuOCCuvnmm+uJJ5442dMDgCijTvYEAOC5Nm3aNODzXXfdVd3d3YO2v+ENb3g5pzWiVq1aVWvWrKnZs2fXhz70oZo9e3YdPHiwHn744brtttvqzjvvrMcff/xkTxMAYghbAF5R3ve+9w34/Mtf/rK6u7sHbX++3t7eGj9+/Es5tRGxefPmWrNmTS1fvrw2bdpUY8aMGfD92rVra+3atcc8RtM0dfDgwRo3btxLOVUAiOFWZADivPWtb63zzjuvHn744br44otr/PjxdcMNN1RV1b333ltLliypadOm1dixY2vOnDm1Zs2aOnLkSP/+11xzTU2cOLF6e3sHHXvFihU1ZcqUAeN/9KMf1YIFC2rChAnV1tZWS5YsqUcfffRFzX3VqlX1mte8pr71rW8NitqqqkmTJtXq1asHbJs5c2a9853vrB//+Mf1pje9qcaNG1ff+MY3qqpq48aNdckll1RnZ2eNHTu2zj333NqwYcOg4x49xkMPPVTz5s2rU089tc4999y65557hpznoUOH6rrrrqvJkyfXhAkTaunSpfXkk0++qHMGgJeasAUg0lNPPVWXXXZZzZs3r9atW1dve9vbqurZxY8mTpxY1113Xa1fv77e+MY31qpVq+r666/v37erq6uefvrpeuCBBwYcs7e3t7Zs2VLvfe97q7W1taqevTV6yZIlNXHixPrCF75QN954Y/3hD3+oiy66qP72t78d15x37NhRO3bsqHe/+901ceLE49r3T3/6U61YsaIuvfTSWr9+fc2bN6+qqjZs2FBnnHFG3XDDDXXbbbfVjBkz6qMf/Wh97WtfG3SMxx57rLq6uuqyyy6rW2+9tUaNGlXLli2r7u7uQWM//vGP1+9///u66aab6uqrr64tW7bUNddcc1xzBoCXTQMAr2Af+9jHmuf/u1q4cGFTVc3tt98+aHxvb++gbVdddVUzfvz45uDBg03TNE1fX18zffr05j3vec+AcXfffXdTVc3Pfvazpmmapqenp+no6GiuuOKKAeN27drVTJo0acD2m266adA8n+/ee+9tqqpZt27dgO19fX3Nk08+OeDv8OHD/d+fccYZTVU1Dz744LDOd/Hixc3s2bMHbDt6jO9///v92/bt29dMnTq1Of/88/u3bdy4samqZtGiRU1fX1//9k9+8pNNa2trs3fv3mOeIwCcDK7YAhBp7Nix9eEPf3jQ9uc+d9rT01N79uypBQsWVG9vb/3xj3+sqmdXXl62bFlt3bq1Dhw40D9+8+bNNX369Lrooouqqqq7u7v27t1bK1asqD179vT/tba21gUXXFA//elPj2vO+/fvr6oadLV23759NXny5AF/v/vd7waMmTVrVi1evPiY57tv377as2dPLVy4sP7yl7/Uvn37BoydNm1aLV26tP9ze3t7feADH6hHHnmkdu3aNWDslVdeOeD1RQsWLKgjR47U3//+9+M6ZwB4OQhbACIdfU3O8z366KO1dOnSmjRpUrW3t9fkyZP7F556buh1dXXVM888U/fdd19VVR04cKC2bt1ay5Yt6w+6xx57rKqqLrnkkkHh+dBDD9Xu3buPa85tbW39v/VcEydOrO7u7uru7q7PfOYzQ+47a9asIbf/4he/qEWLFtWECROqo6OjJk+e3P+88fPDdu7cuYPetXvWWWdVVQ26rfr1r3/9gM+nnXZaVVX95z//eaHTA4CTxqrIAEQaakXgvXv31sKFC6u9vb1uvvnmmjNnTp166qn129/+tj772c9WX19f/9gLL7ywZs6cWXfffXetXLmytmzZUs8880x1dXX1jzk6ftOmTTVlypRBvzdq1PH9Gz3nnHOqqmr79u2DjrNo0aKqqvrXv/417PN9/PHH6+1vf3udc8459ZWvfKVmzJhRY8aMqa1bt9batWsHnO/xOvqM8fM1TfOijwkALxVhC8CrxrZt2+qpp56qe+65py6++OL+7X/961+HHL98+fJav3597d+/vzZv3lwzZ86sCy+8sP/7OXPmVFVVZ2dnf3ieiLPPPrvOPPPM+uEPf1jr1q2rCRMmnNDxtmzZUocOHar77rtvwBXWF7pF+s9//nM1TTPgqu2OHTuq6tlVkwEglVuRAXjVOHqV8blXFf/73//W17/+9SHHd3V11aFDh+rOO++sBx98sJYvXz7g+8WLF1d7e3vdcsstdfjw4UH7v5jX36xevbr27NlTV1xxxZDHPJ4rokOd7759+2rjxo1Djt+5c2f94Ac/6P+8f//+uuuuu2revHlDXpEGgBSu2ALwqvHmN7+5TjvttPrgBz9Yn/jEJ6qlpaU2bdr0grE4f/78mjt3bn3uc5+rQ4cODbgNuerZxZU2bNhQ73//+2v+/Pl1+eWX1+TJk+sf//hHPfDAA/WWt7ylvvrVrx7XHFeuXFnbt2+vW2+9tX71q1/V5ZdfXrNmzaqnn366tm/fXt/5zneqra2t/5nWY3nHO95RY8aMqXe961111VVX1YEDB+qb3/xmdXZ21r///e9B488666z6yEc+Ur/+9a/rta99bd1xxx31xBNPvGAIA0AKV2wBeNU4/fTT6/7776+pU6fW5z//+fryl79cl156aX3xi198wX26urqqp6en5s6dW/Pnzx/0/cqVK+snP/lJTZ8+vb70pS/VtddeW9/97ndr3rx5Q67KPBy33HJLbdu2rc4///y644476uqrr64bb7yxHnnkkfrUpz5VO3bs6L8N+ljOPvvs+t73vlctLS316U9/um6//fa68sor69prrx1y/JlnnlmbN2+urVu31vXXX1+HDx+uzZs3D7naMgAkaWmsAgEAr3ozZ86s8847r+6///6TPRUAGHGu2AIAABBN2AIAABBN2AIAABDNM7YAAABEc8UWAACAaMIWAACAaKOGM6ivr6927txZbW1t1dLS8lLPCQAAgP/nmqapnp6emjZtWp1yyrGvyQ4rbHfu3FkzZswYkckBAADAcP3zn/+s173udcccM6ywbWtr6z9ge3v7ic8MAAAAjmH//v01Y8aM/h49lmGF7dHbj9vb24UtAAAAL5vhPA5r8SgAAACiCVsAAACiCVsAAACiDesZWwAAADheR44cqcOHDw/53ejRo6u1tXVEfkfYAgAAMKKapqldu3bV3r17jzmuo6OjpkyZMqwFoo5F2AIAADCijkZtZ2dnjR8/flC4Nk1Tvb29tXv37qqqmjp16gn9nrAFAABgxBw5cqQ/ak8//fQXHDdu3Liqqtq9e3d1dnae0G3JFo8CAABgxBx9pnb8+PH/59ijY17oOdzhErYAAACMuOE8N3uiz9YeJWwBAACIJmwBAACIJmwBAACIJmwBAAAYcU3TjMiY4RC2AAAAjJjRo0dXVVVvb+//OfbomKP7vFjeYwsAAMCIaW1trY6Ojtq9e3dVPftKn+evftw0TfX29tbu3buro6PjhN5hWyVsAQAAGGFTpkypquqP2xfS0dHRP/ZECFsAAABGVEtLS02dOrU6Ozvr8OHDQ44ZPXr0CV+pPUrYAgAA8JJobW0dsXg9FotHAQAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEE3YAgAAEG3UcAY1TVNVVfv3739JJwMAAABV/9ufR3v0WIYVtj09PVVVNWPGjBOYFgAAAByfnp6emjRp0jHHtDTDyN++vr7auXNntbW1VUtLy4hNEAAAAIbSNE319PTUtGnT6pRTjv0U7bDCFgAAAF6pLB4FAABANGELAABANGELAABANGELAABANGELAABANGELAABANGELAABAtP8BHIV6YIVq5N8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch a sample from each collection\n",
        "print(\"Destinations:\", list(db.collection(\"destinations\").all()))\n",
        "print(\"Attractions:\", list(db.collection(\"attractions\").all()))\n",
        "print(\"Hotels:\", list(db.collection(\"hotels\").all()))\n",
        "print(\"Flights:\", list(db.collection(\"flights\").all()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMWmd28r-Gqt",
        "outputId": "e4778298-7fb6-4f55-dcf7-341cb14d1cfe"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Destinations: []\n",
            "Attractions: []\n",
            "Hotels: []\n",
            "Flights: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cra4Hr3cCFeA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}